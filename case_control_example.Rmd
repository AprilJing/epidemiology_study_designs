---
title: "Case-Control Study Design"
author: "Ryan Gan"
date: "1/29/2017"
output: html_document
---

## Introduction

- This markdown document follows some key concepts outlined in Rothman's *Modern Epidemiology*.

- I used R throughout this presentation to simulate hypothetical data to help visualize case-control studies. 

- I built this presentation using R markdown. Code to reproduce these examples are included

- The following libraries are needed to run the script. Tidyverse contains the 'dplyr' package for data wrangling, and 'ggplot2' for figures. The 'broom' package creates tidy data frames of coefficients from model objects.

```{r libraries,  echo = T, message = F}
# tidyverse package contains dplyr and ggplot packages 
library(tidyverse) 
# broom package allows for easy output of coefficients from models
library(broom)
# nice package for simulating complicated data; uses SEM/DAG principles
library(simcausal) 
# survival package needed for clogit (matched case control)
library(survival)
# matchit package for propensity matching
library(MatchIt)
```

## Background

As epidemiologists, we study the distribution of diseases, and factors that may influence those distributions in populations. Through this process, we hope to either describe distributions of disease to better understand the burden of disease (i.e. prevalence of obesity). Even better, we hope to identify modifiable factors that may explain differences of disease distributions. The ultimate goal is to find these modifiable factors with the hope of intervening to improve population health.

This markdown document focuses on the case-control study design. 

## Case-Control Study 

#### Basic concept

Cases of a specific health outcome are identified from a source population. Controls without the disease are then identified from the same source population. The exposure distribution in cases is then compared to the exposure distribution of the representative control population. The hypothesis tested is that the distribution of exposure is different between cases and controls.

### Source Population
Let's start out with a source population.

I simulated a population of 10,000 individuals. In this simulation, x and y are sequences of values 1 to 100 to allow for plotting, where each circle represents an individual in the population. Right now we don't know anything about their exposure or disease status.

```{r population sim at time 0, message=F}
# simulation population data ----
pop_data <- data_frame(x = rep(seq(from = 1, to = 100, by =1), 100)) %>% 
  arrange(x) %>%  # sort x by ascending values
  cbind(y = rep(seq(from = 1, to = 100, by =1), 100)) 
```

Let's plot the source population at time 0, where each dot represents a subject. 

```{r time 0 plot, message = F}
# plot of population at time 0 ----
ggplot(pop_data, aes(x=x, y=y)) +
  geom_point(color = "grey") +
  # title at time 0
  ggtitle("Population - Time 0") +
  theme(panel.background = element_rect("white"),
        axis.line = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())

```


#### Exposure at Time 0
Let's simulate an exposure distribution for the population, where around 50% of the source population is exposed at time 0. 

The following code is where I created a binary exposure in the population of around 50% exposed (yes), and 50% unexposed (no).

```{r exposure of source population, message=F}
# setting a seed for simulations so they turn out the same each time
set.seed(987)
pop_data <- pop_data %>% 
  # create randomly assigned proportion of disease
  mutate(exposure = rbinom(10000, size = 1, prob = 0.5),
         exp_yn = ifelse(exposure == 1, "Yes", "No"))
```

Let's do some quick descriptive to make sure we correctly simulated a ~50% distribution of exposure in our data.

```{r time 0 exposure stats, message = F}
# cross tabs of exposure
xtabs(~ exp_yn, pop_data) 
# proportion of exposed in source pop
mean(pop_data$exposure) 
```

And let's plot what this exposure might look like in our population.

```{r exp time 0}
# plot of exposure at time 0 ----
ggplot(pop_data, aes(x=x, y=y, color = exp_yn)) +
  geom_point() +
  scale_color_manual(guide = guide_legend("Exposure"), 
                     values = c("aquamarine1", "blue")) +
  # title at time 0
  ggtitle("Population Exposure - Time 0") +
  theme(panel.background = element_rect("white"),
        axis.line = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())
```


#### Disease Incidence at Time 1

We now need to simulate the association between exposure and disease at time 1 (some discrete time later, for example 1 year later).

Let's check back in at time point 1 to measure those who developed disease.

We need to simulate the strength of association and distribution of the disease. We'll use a logistic regression model to define the relationship between exposure and the probability of disease. I want a odds ratio of around ~2.0 and a incidence of disease overall of around ~5%.


```{r simulate exp dis association, message=F}
# finding the formula of the baseline disease probability I want
#1/(1+exp(-(-3.6 + 0.69))) 
# logit relationship between dis and exp
logit_form = -3.33 + 0.69*pop_data$exposure # linear combination with a bias
# define probability of disease given formula
pr = 1/(1+exp(-logit_form))   

# simulate disease
pop_data <- pop_data %>% 
  cbind(disease = rbinom(10000, size = 1, prob = pr)) %>% 
  mutate(dis_yn = ifelse(disease == 1, "Yes", "No"),
         # make 4 category exposure/disease variable
         exp_dis = as.factor(
                   ifelse(exposure == 0 & disease == 0, "Exp = N, Dis = N",
                   ifelse(exposure == 0 & disease == 1, "Exp = N, Dis = Y",
                   ifelse(exposure == 1 & disease == 0, "Exp = Y, Dis = N",
                   ifelse(exposure == 1 & disease == 1, "Exp = Y, Dis = Y", 
                          NA))))))
```

Let's check some summary statistics on our simulated data to make sure our data look as expected.

```{r pop exp dis summary stats, message=F}
# check to make sure disease in population is around ~5%
mean(pop_data$disease) 
# 2x2 table
pop_tab <- xtabs(~exp_yn + dis_yn, pop_data)
pop_tab
# exposure proportion given disease
prop.table(pop_tab, 2)
```

Let's plot this population now.

```{r plot exp dis time 1, message=F}
# plot of population exposure/disease 
ggplot(pop_data, aes(x=x, y=y, color = exp_dis, shape = exp_dis)) +
  geom_point() +
  scale_color_manual(guide = guide_legend("Exposure/Disease"), 
                     values = c("aquamarine1", "aquamarine1", "blue", "blue")) +
  # custom shape
  scale_shape_manual(guide = guide_legend("Exposure/Disease"), 
                     values = c(19, 25, 19, 25)) + 
  # title at time 0
  ggtitle("Population Exposure/Disease - Time 1") +
  theme(panel.background = element_rect("white"),
        axis.line = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())
```

Now that we have defined our exposure/disease association in the population, we can calculate a couple measures of association. For simplicity, we will calculate the risk ratio, risk difference, and odds ratio. All of these are appropriate measures of association to calculate in a population.

**Population Risk Ratio**
```{r pop risk ratio, message = F}
# risk ratio model
rr_mod <- tidy(glm(disease ~ exposure, data = pop_data,
                       family = "poisson"(link="log"))) 
# risk ratio estimate
exp(rr_mod[2,2])
```

For our risk ratio, we can interpret this as those exposed have a 2.14 times (114%) increase in risk for disease relative to those not exposed. 

**Population Risk Difference**
```{r pop risk difference, message = F}
# risk difference model
rd_mod <- tidy(glm(disease ~ exposure, data = pop_data,
                       family = "binomial"(link="identity"))) 
# risk difference estimate
rd_mod[2,2]
```

For our risk difference, we can interpret this as the risk for disease is ~3.6% higher in those exposed compared to those unexposed.

**Population Odds Ratio**
```{r pop odds ratio, message = F}
# odds ratio model
or_mod <- tidy(glm(disease ~ exposure, data = pop_data,
                       family = "binomial"(link="logit"))) 
# odds ratio estimate
true_or <- exp(or_mod[2,2])
true_or 
# I'm creating this object for latter use
```

For the odds ratio, we may interpret this as the odds of disease in the exposed group is 2.22 times (122%) higher than the odds of disease in the unexposed group. Notice how close this estimate is to our estimate of the risk ratio. This is what they mean by the 'rare disease' assumption, where when the disease is rare, the odds ratio approximates the risk ratio. Thus, we could interpret the odds ratio the same way we interpret the risk ratio. If you look at the 2x2 table closely, it should make sense why the OR is so close to the RR.

Since this is our source population, these estimates are the 'true' estimates of our exposure/disease relationship. We don't need to calculate confidence intervals around these estimates.

### Selecting Cases and Controls

Why use a case-control study over some other studies? Well, if done correctly, it's a very efficient. Both in number of people needed and cost. I have used case-control studies usually in an existing cohort (nested case-control), where I wanted to look at the association between an expensive biomarker and a defined outcome. Another good example are genome-wide association studies (GWAS), where genotyping participants is very expensive. Therefore these studies often recruit cases of an outcome (e.g. rheumatoid arthritis), and then recruit suitable controls. The frequency of certain single-nucleotide polymorphisms (SNPs) are then compared between cases and controls. If it's not difficult to recruit subjects or measure exposure, then perhaps another study design besides the case-control design should be considered.

For both cases and controls...

1. Define your source population.

#### Case Selection

1. Cases need to be selected from the source population (a pattern is beginning to emerge). 
Hopefully not much more needs to be said about this. You can't use results from your case-control population to
make inference about the relationship between exposure and disease in the source population. For example, if you were interested on factors associated with concussions in football players, you wouldn't want to recruit concussion cases in baseball players. 

2. Have a well-defined outcome. 

Be as specific as you can. It makes it easier to identify your cases. For example, you could define 'arthritis' as your outcome, but this could include osteoarthritis (wear and tear arthritis). If you were really interested in autoimmune arthritis, you would pick an outcome like 'rheumatoid arthritis'. Along these lines, you can even be more specific. Do you want self-reported rheumatoid arthritis? Physician-diagnosed rheumatoid arthritis? Or rheumatoid arthritis as diagnosed by a board-certified rheumatologist using the 2010 ACR/EULAR criteria? As you are probably learning, epidemiology is all about trade-offs. With very specific outcomes (like the last one), it may be more difficult or expensive to find these cases. But if we just used the first example of 'arthritis', that may not be specific enough to appropriately answer our research question as the pathophysiology or factors that are associated with that outcome could be very different that our more specific outcomes.

3. Selection of cases needs to be independent of exposure. 

If you consider exposure in your selection of cases, you will bias the exposure distribution of your sampling cases. We'll come back to this example when we select some cases and controls from our simulated source population.

#### Control Selection

1. Controls need to be selected from the same source population the cases were selected from (looks like the source population is important). As stated in *Modern Epidemiology 3rd Edition*.

> Controls should be selected from the same population--the source population--that gives rise to the study cases. If this rule cannot be followed, there needs to be solid evidence that the population supplying controls has an exposure distributoin identical to that of the population that is the source of cases, which is a very stringent demand that is rarely demonstrable.

Again, this should make sense. We likely wouldn't want to compare cases of concussions in football players to controls (no concussion) sampled from baseball players. Especially if 'tackling' was our exposure of interest as the distribution of tackles in football is much higher than the distribution of tackles in baseball (which hopefully is 0). 
However, as Rothman et al. point out, there may be reasons why you might sample controls from a different source population if it can be shown the distribution of exposure would be similar to the source population of cases. This is nearly impossible to do, so it's just best to make sure your cases and controls come from the same source population. 

2. Controls should be at risk for developing the outcome. 

This isn't directly stated in *Modern Epidemiology*, but this should be considered when selecting controls. Ask yourself, are these controls at risk of developing disease? A classic example (I think) is a case-control study of ovarian cancer in women, where the control group contained fair amount of hospital controls that contained women who had hysterectomy. These women were not at risk of developing ovarian cancer and therefore not appropriate controls.

3. Selection of controls needs to be independent of exposure. Furthermore, Rothman et al goes on to say...

> Within strata or factors that will be used for stratification in the analysis, controls should be selected independently of their exposure status, in that the sampling rate for controls should not vary with exposure.

### Assessing Exposure in Case-Control Studies

Once you have selected your cases and controls, we then compare the distribution of exposure in the cases to that of the controls. This is the main hypothesis we test. Namely the proportion/mean/whatever of exposure in cases is different from proportion/mean/whatever of exposure in cases.

There is one rule for assessing exposure.

1. Exposure *should* be antecedent (happen before) of the disease.

This should make sense too. You wouldn't want to look at an 'exposure' that may have happened after disease occurred. For example, you wouldn't want to find cases of people with high blood pressure and controls without high blood pressure and compare salt intake a couple years after case/control status was assessed as cases with high blood pressure may have lower sodium intake relative to controls.

2. Selection of cases and controls should be independent of exposure status. 

This is a rehash again, but should make sense by now. For example, we don't want to select disease cases, but then decide we only want disease cases that were exposed. That would bias our estimates of association.

## Case-Control Selection from Source Data

I think these concepts will be easier to understand with our simulated data. So lets select some cases from our simulated source population. Let's start by selecting all our cases since we really only have ~570 cases.

```{r casecontrol data, message=F}
# output the cases
all_cases_data <- pop_data %>% 
  filter(disease == 1) 

# set seed for random sample to make sure it reproduces each time
set.seed(123)
# pick double the controls
sample_control_data <- pop_data %>% 
  filter(disease == 0) %>% 
  sample_n(2*nrow(all_cases_data))


# row bind the two dataframes together
case_control_data1 <- bind_rows(all_cases_data, sample_control_data)
```

Let's plot our selected cases and controls. They will still maintain the same positions they had in the source population.

```{r casecontrol 1 plot, message = F}
# plot of population exposure/disease 
ggplot(case_control_data1, aes(x=x, y=y, color = exp_dis, shape = exp_dis)) +
  geom_point() +
  scale_color_manual(guide = guide_legend("Exposure/Disease"), 
                     values = c("aquamarine1", "aquamarine1", "blue", "blue")) +
  # custom shape
  scale_shape_manual(guide = guide_legend("Exposure/Disease"), 
                     values = c(19, 25, 19, 25)) + 
  # title at time 0
  ggtitle("Case-Control Sample (all cases and 2x controls)") +
  theme(panel.background = element_rect("white"),
        axis.line = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        axis.ticks = element_blank())
```

We'll aslo calculate some descriptive statistics. 

```{r casecontrol 1 states, message = F}
# cross tabs of exposure
cc_tab1 <- xtabs(~ exp_yn + dis_yn, case_control_data1) 
cc_tab1
# proportion of exposure, given disease
prop.table(cc_tab1, 2)

```

You can see from the above 2x2 table, that the proportion of exposure in controls (disease no), is roughly equivalent to our sample, where the controls had a proportion of exposure of ~0.49, and in the sample population, those without the disease had a proportion of exposure of ~0.49.

```{r casecontrol association, message = F}
# dataframe of odds ratio
cc_or_mod <- tidy(glm(disease ~ exposure, data = case_control_data1,
             family = "binomial"(link="logit")))

odds_ratio <- round(exp(cc_or_mod[2, 2]),2)
lower_bound <- round(exp(cc_or_mod[2, 2] - (1.96*cc_or_mod[2,3])),2)
upper_bound <- round(exp(cc_or_mod[2, 2] + (1.96*cc_or_mod[2,3])),2)

# names vector
names <- c("OR", "95% CI Lower", "95% CI Upper")
# OR estimates vector
dis_given_exp <- c(odds_ratio, lower_bound, upper_bound)
or_estimates <- rbind(names, dis_given_exp)
or_estimates
```

The interpretation of the odds ratio here is 'cases are 2.19 times (119%) more likely to be exposed than controls. We are 95% confident that the true odds ratio estimate lies between 1.76 and 2.74'.

You may have heard in previous classed or in text books that we interpret the odds of exposure, given disease in a case-control study. You might think it's the way the odds ratio is calculated, but it's actually because the way the case-control study is designed. Where we first identify cases and controls, and then look back in time to assess exposure. Hence why we interpret odds of exposure given disease. I'm actually not sure if this is still a thing.

As *Modern Epidemiology* points out, our estimate of association (odds ratio) in a case-control study will represent the population odds ratio when the exposure proportion in the control group represents the the exposure proportion of those without the disease in the source population. Also notice that the odds ratio from our case-control study will approximate the risk ratio when the disease in the population is rare.

**The odds ratio from a case-control study will represent the true risk ratio in the source population when the outcome is rare <5%-10% and the exposure distribution of controls is approximately equivalent to the no disease group of the source population.**

*Why can't we calculate a risk difference?*

By design, case-control study designs define the distribution of disease, given exposure. In our example here, we made the proportion of our disease ~33% (cases make up 1/3 of the study), where our source population had a proportion of disease of ~5%. Let's calculate the risk difference.

```{r risk diff in case control, message=F}
# risk difference model
rd_mod <- tidy(glm(disease ~ exposure, data = case_control_data1,
                       family = "binomial"(link="identity"))) 
# risk difference estimate
rd_mod[2,2]
```

As you can see, we've drastically overestimated the risk difference. Don't calculate risk differences in a case-control study. 

### Case-Control in Practice

In practice, it's still expensive or impractical to sample all cases from a source population. Let's do a 1 to 1 sampling where for each case we select one control. 

```{r case control n needed, message=F}
n_case_control <- seq(from = 10, to = 500, by = 10)

# create empty matrix 
bias_matrix <- matrix(nrow = length(n_case_control), ncol = 4)
# col names
colnames(bias_matrix) <- c("samp_n", "perc_bias_median", 
                           "perc_bias_lower", "perc_bias_upper")

set.seed(123)
# double loop where I run models based on i number of cases and controls

for(i in 1:length(n_case_control)){
  # fill sample size column of empty matrix
  bias_matrix[i,1] <- n_case_control[i]
  
  # empty vector to populate with % bias
  or_vector <- vector(mode="double", length = 1000)
  
  # repeate process 100 times to estimate a distribution of bias 
  for(j in 1:100){
    case_control_data <- pop_data %>% 
    # create selection variable
      group_by(disease) %>% 
      do(sample_n(.,n_case_control[i]))

    # or mod
    cc_or_mod <- tidy(glm(disease ~ exposure, data = case_control_data,
                   family = "binomial"(link="logit")))
    # estimate odds ratio
    odds_ratio <- round(exp(cc_or_mod[2, 2]),2)
    # calculate percent bias (difference from sample vs true)
    perc_bias <- (true_or - odds_ratio)/true_or
    # fill vector
    or_vector[j] <- perc_bias
    
  } # end first loop repeated sampling
  # take the median of the vectors
  or_est <- quantile(or_vector, c(0.01, 0.5, 0.99))
  # fill bounds of matrix
  bias_matrix[i, 3] <- or_est[1]
  bias_matrix[i, 2] <- or_est[2]
  bias_matrix[i, 4] <- or_est[3]
}  # end loop

# set permanent dataframe
bias_df <- as.data.frame(bias_matrix)

# plot of bias as sample size increases
ggplot(bias_df, aes(x=samp_n)) +
  geom_ribbon(aes(ymin=perc_bias_lower, ymax=perc_bias_upper), alpha=0.4,
              fill = "blue") +
  geom_line(aes(y = perc_bias_median), color = "blue") +
  ggtitle("Percent Bias vs. Sample Size (99% Bounds)") +
  ylab(expression("Percent Bias (% Estimated OR is Different from True OR)")) +
  xlab('1x1 Sample Size of Cases and Controls') + 
  theme(panel.background = element_rect(fill = 'white', colour = 'black'),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    axis.text.x = element_text(size = 12),
    axis.text.y = element_text(size = 12),
    axis.title.y = element_text(angle = 90, size = 12),
    axis.title.x = element_text(size = 14), 
    strip.background = element_rect(fill = 'white')) 

```

This plot shows the range of percent bias of beta estimates [(True Odds Ratio - Case-Control Odds Ratio)/ True Odds Ratio] improves as sample size increases. The closer to 0, the less bias. Notice the median estimate (blue line running right across 0) is perfectly at 0, suggesting no bias. This is a good example of why it's important to replicate. Over 1000 replicates, the median values of all those replicates has no bias. However, you can see the 99% bounds based on sample size narrow as sample size increases. I'd say that around 100 cases and controls, sample size may stablize a bit.

This is probalby not new information, but the more cases and controls you have, the better.

## Confounding Bias in Case-Control Studies

As with any epidemiologic study, we have to deal with confounding. Let's simulate one confounding factor (Sex) in to our study design. 

```{r confounding sex, message=F}
# this chunk of code uses the simcausal package
c_sex_dag <- DAG.empty()

c_sex_dag <- c_sex_dag +
  # binary sex distribution
  node("Sex", distr = "rcat.b1", prob = c(0.5, 0.5)) +
  # age continuous 
  node("Exp", distr = "rbern", 
       prob = plogis(-3.0 + 2 * Sex)) +  
  node("Dis", distr = "rbern",
  prob = plogis(-0.5 + 0.69 * Exp + -2 * Sex))
  
c_sex_dag <- set.DAG(c_sex_dag)

# plot DAG
plotDAG(c_sex_dag, xjitter = 0.3, yjitter = 0.04,
        edge_attrs = list(width = 0.5, arrow.width = 1.5, arrow.size = 0.4),
        vertex_attrs = list(size = 12, label.cex = 0.8))

# simulate causal structure
c_sex_df <- sim(DAG = c_sex_dag, n = 10000, rndseed = 321) %>% 
  mutate(Sex = ifelse(Sex == 2, 1, 0))
```

Now that we simulated a popualtion of 10,000 with approximaly the same distribution of exposure and disease with sex as confounding variabls, we'll calculate some summary statistics and the 'true' association between exposure and disease. 

```{r pop confounding sex, message=F}
summary(c_sex_df)

true_est <- tidy(glm(Dis~ Exp + Sex, 
                     data = c_sex_df, family = "poisson"))
# true risk ratio estimate exposure/disease association
rel_risk <- exp(true_est[2,2])
rel_risk
```

In order to etimate the 'true' association between exposure and disease (risk ratio 2.11), we need to adjust for sex. 

Let's see what happens when we create a case control study with a sample size of 100 cases and 100 controls.

```{r case control confounding sex , message=F}
set.seed(123)
case_control_data <- c_sex_df %>% 
  # create selection variable
  group_by(Dis) %>% 
  do(sample_n(.,100))

# 2x2 table exposure by disease crude
xtabs(~ Exp + Dis, case_control_data)

# regression model (unadjusted)
casecont_est <- tidy(glm(Dis~ Exp , 
  data = case_control_data, family = "binomial"(link="logit"))) %>% 
  mutate(OR = exp(estimate),
         Lower_95 = exp(estimate - (1.96*std.error)),
         Upper_95 = exp(estimate + (1.96*std.error))) %>% 
  filter(term == "Exp") 
# estimate crude odds ratio and 95% bounds
casecont_est <- round(casecont_est[, 6:8],2)
casecont_est
```

We can test the confounding assumption in our case-control data. Is sex associated with exposure? Is sex associated with disease?


```{r sex bivariate association in casecontrol, message=F}
# 2x2 exposure by sex
xtabs(~ Exp + Sex, case_control_data)
# regression model sex -> exposure
casecont_est <- tidy(glm(Exp ~ Sex , 
  data = case_control_data, family = "binomial"(link="logit"))) %>% 
  mutate(OR = exp(estimate),
         Lower_95 = exp(estimate - (1.96*std.error)),
         Upper_95 = exp(estimate + (1.96*std.error))) %>% 
  filter(term == "Sex") 
# estimate odds ratio and 95% bounds
casecont_est <- round(casecont_est[, 6:8],2)
casecont_est


# 2x2 disease by sex
xtabs(~ Dis + Sex, case_control_data)
# regression model sex -> exposure
casecont_est <- tidy(glm(Dis ~ Sex , 
  data = case_control_data, family = "binomial"(link="logit"))) %>% 
  mutate(OR = exp(estimate),
         Lower_95 = exp(estimate - (1.96*std.error)),
         Upper_95 = exp(estimate + (1.96*std.error))) %>% 
  filter(term == "Sex") 
# estimate odds ratio and 95% bounds
casecont_est <- round(casecont_est[, 6:8],2)
casecont_est

```
  
Our crude odds ratio for this case-control sample suggests no association between exposure and disease (OR:1.08, 95%CI: 0.62-1.89). However, we know sex is a confounding variable based on our simulation.

```{r case control adj model}
# 2x2 table, stratified by sex
xtabs(~ Exp + Dis + Sex, case_control_data)
# even without calculating proportions, it's pretty clear the disease and exposure
# is more likely in Sex == 1, 

# regression model (adjusted)
casecont_est <- tidy(glm(Dis~ Exp + Sex, 
  data = case_control_data, family = "binomial"(link="logit"))) %>% 
  mutate(OR = exp(estimate),
         Lower_95 = exp(estimate - (1.96*std.error)),
         Upper_95 = exp(estimate + (1.96*std.error))) %>% 
  filter(term == "Exp") 
  # estimate adjusted odds ratio and 95% bounds
casecont_est <- round(casecont_est[, 6:8],2)
casecont_est
```

When we adjust for sex, we arrive at the appropriate estimate between exposure and disease. We'd conclude there is a significant association between exposure and disease, adjusting for sex (OR:2.92, 95%CI:1.40-6.11).

**Key Point: Confounding can be accounted for in case-control designs via adjustment (Mantel-Hanzel, logistic regression).**

## Matched Case-Control Studies

Another variant of the case-control study commonly used in clinical studies is the matched case-control study. In this study design, a case is identified, and then matched to n controls based on potential confounders. For many clinicians I met, this type of design made intuitive sense as a way to control confounding. From an epidemiologits' stand point, the big benefit of a matched design over a standard case-control study is that you can increase your statistical efficiency, meaning you need fewer cases and controls. Furthermore, if the matching are not truly confounders, then matching is of no benefit. There is another big nuances about matching in case-control studies, where by design, you have introduced a bias that must be accounded for. For further reading, see *Modern Epidemiology* page 175.  

Example of a 1 to 1 matched design. Let's take 100 random cases and match them to 100 controls based on our confounding variable sex.

```{r 1 to n matched case-control, message = F}
# sloppy code to match. One day I may make a formula for 1x1 matching
# random subset of cases:
set.seed(123)
cases <- c_sex_df %>% 
  filter(Dis == 1) %>% 
  sample_n(100)

control <- c_sex_df %>% 
  filter(Dis == 0)

# number of controls per case
  n_control <- 1
  seed_num <- 123

# create empty dataframe
matched_df <- data_frame()

# loop through each case and find matched controls
for(i in 1:nrow(cases)){
  case_i <- cases[i,] 
  set.seed(seed_num)
  case_control_i <- bind_rows(case_i, control[(sample(
    which(control[,2] == case_i[1,2]), n_control, replace = F)),]) %>% 
    mutate(match_id = i)

  # this pops out a warning message the first time through as there
  # is no ID yet
  # fill case_control_data
  matched_df <- bind_rows(matched_df, case_control_i)
  
  # exclude controls already selected from pool so they aren't sampled again
  control <- control[!(control$ID %in% matched_df$ID), ]
}

# Now that we've matched on sex, let's look at some contingency tables
# sex and exposure
xtabs(~ Sex + Exp, c_sex_df)
# sex and disease
xtabs(~ Sex + Dis, c_sex_df)
# Source Population 
xtabs(~Dis + Exp + Sex, c_sex_df)

# regression model (unadjusted)
pop_est <- tidy(glm(Dis~ Exp, 
  data = c_sex_df, family = "poisson"(link="log"))) %>% 
  mutate(OR = exp(estimate),
         Lower_95 = exp(estimate - (1.96*std.error)),
         Upper_95 = exp(estimate + (1.96*std.error))) %>% 
  filter(term == "Exp") 
  # estimate adjusted odds ratio and 95% bounds
pop_est <- round(pop_est[, 6:8],2)
pop_est

# adjusted 
pop_est <- tidy(glm(Dis~ Exp + Sex, 
  data = c_sex_df, family = "poisson"(link="log"))) %>% 
  mutate(OR = exp(estimate),
         Lower_95 = exp(estimate - (1.96*std.error)),
         Upper_95 = exp(estimate + (1.96*std.error))) %>% 
  filter(term == "Exp") 
  # estimate adjusted odds ratio and 95% bounds
pop_est <- round(pop_est[, 6:8],2)
pop_est


# Disease by Sex
xtabs(~ Sex + Dis, matched_df)

# case control population
xtabs(~Dis + Exp + Sex, matched_df)

# matched df ----
# case control population
xtabs(~Dis + Exp + match_id, matched_df)

# regression model (unadjusted)
match_est <- tidy(glm(Dis~ Exp, 
  data = matched_df, family = "binomial"(link="logit"))) %>% 
  mutate(OR = exp(estimate),
         Lower_95 = exp(estimate - (1.96*std.error)),
         Upper_95 = exp(estimate + (1.96*std.error))) %>% 
  filter(term == "Exp") 
  # estimate adjusted odds ratio and 95% bounds
match_est <- round(match_est[, 6:8],2)
match_est

# adjusted
# regression model (adjusted)
match_adj_est <- tidy(glm(Dis~ Exp + Sex, 
  data = matched_df, family = "binomial"(link="logit"))) %>% 
  mutate(OR = exp(estimate),
         Lower_95 = exp(estimate - (1.96*std.error)),
         Upper_95 = exp(estimate + (1.96*std.error))) %>% 
  filter(term == "Exp") 
  # estimate adjusted odds ratio and 95% bounds
match_adj_est <- round(match_adj_est[, 6:8],2)
match_adj_est


# conditional odds ratio
head(matched_df)

table(exposure = matched_df$Exp, )

?table
?separate


stocks <- data_frame(
  time = as.Date('2009-01-01') + 0:9,
  X = rnorm(10, 0, 1),
  Y = rnorm(10, 0, 2),
  Z = rnorm(10, 0, 4)
)

head(stocks)
gather(stocks, stock, price, -time)
stocks %>% gather(stock, price, -time)


head(concord_discord_pairs)
 
match_melt <- melt(matched_df, id = c("match_id", "Dis", "Exp"))   

match_spread <- dcast(matched_df, match_id ~ Exp, value.var = c("Exp"), fun = sum)



model <- clogit(Dis ~ Exp + strata(match_id), matched_df)
summary(model)

summary(glm(Dis ~ Exp + Sex, matched_df, family = "binomial"))
exp(0.72)


```

In the matched design, you may gain statistical efficiency, but you introduce a bias that needs to be accounted for either by adjustment (Mantel-Hanzel, regression), or the conditional odds ratio, which is a pain to calculate. I'm trying to figure out how to make it easy to calculate in this dataframe.

```{r frequency/propensity matching , message = F}
# using the same slected cases, we put them in a dataset with all our controls
df_to_prop_match <- bind_rows(cases, control)

# you can match on disease, just don't match on exposure since we
# want to evaluate exposure in cases vs controls
prop_match1 <- matchit(Dis~ Sex , data = df_to_prop_match, 
                       method="nearest", distance="logit", ratio = 1)
#To obtain matched data, type the following command,
prop_matched_data <- match.data(prop_match1)
#check balance
summary(prop_matched_data)
# notice you get a weights, and notice here how they are 1 as there 
# are perfect matches

# estimate
summary(glm(Dis ~ Exp , prop_matched_data, family = "binomial")) 
# again, if you don't adjust for Sex, your estimates are biased a tad
summary(glm(Dis ~ Exp + Sex, prop_matched_data, family = "binomial")) 


```

So in summary, there are multiple ways to account for confounding variables in case-control designs. In my opinion, exact matching is probably the biggest pain unless you really think you need statistical efficiency. Logistic regression with adjustments will serve you pretty well. But at least you are aware of the other ways this was done in the past.

```{r confounding age and sex, message=F, eval = F}
# this chunk of code uses the simcausal package
confounding_dag <- DAG.empty()

confounding_dag <- confounding_dag +
  # binary sex distribution
  node("Sex", distr = "rcat.b1", prob = c(0.5, 0.5)) +
  # age continuous 
  node("Age", distr = "rnorm", mean = 45, sd  = 10) +
  node("Exp", distr = "rbern", 
       prob = plogis(1 + -0.05 * Age + 1 * Sex)) +  
  node("Dis", distr = "rbern",
  prob = plogis(-7 + 0.69 * Exp + 0.1 * Age + -0.5 * Sex))
  
confounding_dag <- set.DAG(confounding_dag)

# plot DAG
plotDAG(confounding_dag, xjitter = 0.3, yjitter = 0.04,
        edge_attrs = list(width = 0.5, arrow.width = 1.5, arrow.size = 0.4),
        vertex_attrs = list(size = 12, label.cex = 0.8))

# simulate causal structure
pop_confound_df <- sim(DAG = confounding_dag, n = 10000, rndseed = 321) %>% 
  mutate(Sex = ifelse(Sex == 2, 1, 0))
```

Now that we simulated a popualtion of 10,000 with approximaly the same distribution of exposure and disease with age and sex as confounding variables, we'll calculate some summary statistics and the 'true' association between exposure and disease.

```{r pop confound sim stats, message=F, eval = F}
summary(pop_confound_df)

true_est <- tidy(glm(Dis~Exp + Age + Sex, 
                     data = pop_confound_df, family = "poisson"))
# true risk ratio estimate exposure/disease association
rel_risk <- exp(true_est[2,2])
rel_risk
```
